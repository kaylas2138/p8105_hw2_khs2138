---
title: "p8105_hw2_khs2318"
author: "Kayla Schiffer-Kane"
date: "2023-10-04"
output: 
  github_document:
    toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(message = FALSE)
```

```{r libraries}
library(tidyverse)
library(readxl)
```

# Problem 1 

Dataset is FiveThirtyEight data 

## Clean pols_month

Clean the data in pols-month.csv. Use `separate()` to break up the variable mon into integer variables `year`, `month`, and `day`; replace `month` number with month name; create a `president` variable taking values `gop` and `dem`, and remove `prez_dem` and `prez_gop`; and remove the `day` variable.
 

```{r clean_pols_month}
pols_month =
  read_csv('./data/fivethirtyeight_datasets/pols-month.csv') |>
  separate(mon, c("year","month","day")) |>
  mutate(month = month.name[as.numeric(month)]) |>
  mutate(president = recode(prez_dem, "1" = "dem", "0" = "gop")) |>
  select(-prez_dem,-prez_gop, - day)
  
#head(pols_month)
```


## Clean snp 

Second, clean the data in snp.csv using a similar process to the above. For consistency across datasets, arrange according to year and month, and organize so that year and month are the leading columns.

```{r clean_snp}
snp =
  read_csv('./data/fivethirtyeight_datasets/snp.csv') |>
  separate(date, c("month","day","year"), sep = '/') |>
  mutate(month = month.name[as.numeric(month)]) |>
  mutate(year = if_else(year > 15, paste0("19",year), paste0("20",year))) |> 
  #arrange(year, month) |>
  select(year,month,close)
#tail(snp)
```


## Clean Unemployment
Third, tidy the unemployment data so that it can be merged with the previous datasets. This process will involve switching from “wide” to “long” format; ensuring that key variables have the same name; and ensuring that key variables take the same values.


```{r clean_unemployment}
unemployment =
  read_csv('./data/fivethirtyeight_datasets/unemployment.csv') |> 
  pivot_longer(Jan:Dec,
               names_to = "month",
               values_to = "percentage") |>
  janitor::clean_names() |>
  mutate(month = month.name[match(month, month.abb)]) |> # Jan -> January 
  mutate(year = as.character(year))
#unemployment
```

## Merge all data
Required casting year in unemployment to character

```{r merge_538}
data = 
  left_join(pols_month, snp) |>
  left_join(x = _, y = unemployment)
```

The resulting dataset has `r nrow(data)` rows and `r ncol(data)` columns. 

* Pols_month has  `r nrow(pols_month)` rows, and we created `president` which tells us if the president was a gop/dem in a given year. This column was created from a combination of `prez_gop` and `prez_dem`, which I tested to make sure are truly mutually exclusive. Years include `r min(pols_month$year)` to `r max(pols_month$year)`
* SNP has `r nrow(snp)`, with data from `r min(snp$year)` to `r max(snp$year)`. Average close price for these years is `r filter(snp, close >= 0) |> pull(close) |> mean()`
* Unemployment has unemployment rates from `r min(unemployment$year)` to `r max(unemployment$year)`. Average unemployment for these years is `r filter(unemployment, percentage >= 0) |> pull(percentage) |> mean()`
* Because the years don't overlap exactly, we'll miss some data for certain years - hence the "NAs" in the merged dataset - 36 values are missing SNP close price `close`, and 12 are missing unemployment rates `percentage`.


# Problem 2 

## Load and Clean Data
Read and clean the Mr. Trash Wheel sheet:

* specify the sheet in the Excel file and to omit non-data entries (rows with notes / figures; columns containing notes) using arguments in read_excel
* use reasonable variable names
* omit rows that do not include dumpster-specific data

* The last row contains sums of the previous so should be excluded. This is the only row where date is missing, so excluding it by filtering out where Month is null. 

```{r load_trashwheel}
mr_data = read_excel("./data/202309 Trash Wheel Collection Data.xlsx",
                             sheet = "Mr. Trash Wheel",
                             skip = 1,
                             range = cell_cols("A:N")) |>
  filter(!is.na(Month)) |> 
  janitor::clean_names() |> 
  mutate(name = "mr_trash_wheel") |> 
  mutate(year = as.numeric(year))
#skimr::skim(mr_data)

#mr_data
```

## Calculate homes_powered

The data include a column for the (approximate) number of homes powered. This calculation is described in the `Homes powered note`, but not applied to every row in the dataset. Update the data to include a new `homes_powered` variable based on this calculation.

* From excel: Homes Powered - Each ton of trash equates to on average 500 kilowatts of electricity. An average household will use 30 kilowatts per day.

```{r homes_powered}
kw_per_ton = 500
kw_per_house = 30
mr_data = mr_data |>
  rename(homes_powered_orig = homes_powered) |>
  mutate(homes_powered = (weight_tons * kw_per_ton / kw_per_house))
```

**Checking** to see if the calculation looks similar to the original `homes` column. Using only where the homes_powered from original dataset was  calculated, the average number of homes powered is `r mr_data |> filter(homes_powered_orig > 0) |> pull(homes_powered_orig) |> mean() |> round(2)` compared to our calculation, `r pull(mr_data, homes_powered) |> mean() |> round(2)`. These are fairly equivalent. 

## Professor and Gwynnda Trash Wheels

Use a similar process to import, clean, and organize the data for Professor Trash Wheel and Gwynnda, and combine these with the Mr. Trash Wheel dataset to produce a single tidy dataset. To keep track of which Trash Wheel is which, you may need to add an additional variable to all datasets before combining.

### Load and Clean Professor Trash Wheel


```{r professor}
prof_data = read_excel("./data/202309 Trash Wheel Collection Data.xlsx",
                             sheet = "Professor Trash Wheel",
                             skip = 1,
                             range = cell_cols("A:M")) |>
  filter(!is.na(Month)) |> 
  janitor::clean_names() |> 
  mutate(homes_powered = (weight_tons * kw_per_ton / kw_per_house)) |> 
  mutate(name = "professor_trash_wheel")
#skimr::skim(prof_data)

#prof_data

```

### Load and Clean Gwynnda Trash Wheel


```{r gwynnda}
gwyn_data = read_excel("./data/202309 Trash Wheel Collection Data.xlsx",
                             sheet = "Gwynnda Trash Wheel",
                             skip = 1,
                             range = cell_cols("A:L")) |>
  filter(!is.na(Month)) |> 
  janitor::clean_names() |> 
  mutate(homes_powered = (weight_tons * kw_per_ton / kw_per_house)) |> 
  mutate(name = "gwynnda_trash_wheel")
#skimr::skim(gwyn_data)
#gwyn_data
```


### Combine Data Sets
```{r bind_trash}
trash_tidy = 
  bind_rows(mr_data, prof_data, gwyn_data) |>
  select(name, everything(), -homes_powered_orig)

#head(trash_tidy)
#unique(trash_tidy$name)
```


## Summary of Data 
There are `r nrow(mr_data)` observations from Mr. Trash Wheel, `r nrow(prof_data)` observations from Professor Trash Wheel, and `r nrow(gwyn_data)` observations from Gwynnda Trash Wheel. 

* Gwynndata is missing `sports` and `glass_bottles`. `wrappers` values are missing for many of the rows. There is also one dumpster number listed twice with different data (#21)

* Professor Trash Wheel doesn't have `sports` column. Professor Trash Wheel has one row missing many of the variables

* These match the combined dataset counts: `r trash_tidy |> filter(name == "mr_trash_wheel") |> nrow()`, `r trash_tidy |> filter(name == "professor_trash_wheel") |> nrow()`, and `r trash_tidy |> filter(name == "gwynnda_trash_wheel") |> nrow()`, respectively. 

* The average number of estimated homes powered overall is `r trash_tidy |> pull(homes_powered) |> mean() |> round(2)`. For each trash wheel, the average is `r trash_tidy |> filter(name == "mr_trash_wheel") |> pull(homes_powered) |> mean() |> round(2)` for Mr. Trash Wheel, `r trash_tidy |> filter(name == "professor_trash_wheel") |> pull(homes_powered) |> mean() |> round(2)` for Professor Trash Wheel, and `r trash_tidy |> filter(name == "gwynnda_trash_wheel") |> pull(homes_powered) |> mean() |> round(2)` for Gwynnda Trash Wheel, 

* The total weight of trash collected by professor trash_wheel is `r trash_tidy |> filter(name == "professor_trash_wheel") |> pull(weight_tons) |> sum()` tons. 

* The total number of cigarette butts collected by Gwynnda in July 2021 is `r trash_tidy |> filter(name == "gwynnda_trash_wheel", month == "July", year == 2021) |> pull(cigarette_butts) |> sum()`


# Problem 3

## Baseline Demographics

Import, clean, and tidy the dataset of baseline demographics. 
* Ensure that sex and APOE4 carrier status are appropriate encoded (i.e. not numeric)
* Remove any participants who do not meet the stated inclusion criteria (i.e. no MCI at baseline).

```{r load_mci, warning = FALSE}
mci_baseline_all =
  read_csv('./data/data_mci/MCI_baseline.csv', skip = 1) |>
  janitor::clean_names() |>
  mutate(age_at_onset = as.numeric(age_at_onset)) |> 
  mutate(sex = recode(sex, "0" = "Female", "1" = "Male")) |>
  mutate(sex = as.factor(sex)) |>
  mutate(apoe4 = recode(apoe4, "0" = "non_carrier", "1" = "carrier")) |>
  mutate(apoe4 = as.factor(apoe4))

mci_baseline = mci_baseline_all |>
  filter(!is.na(age_at_onset))

#skimr::skim(mci_baseline)
#head(mci_baseline)
```

Age at onset is converted to numeric, as it is stored as a character. Sex is converted from binary to a factor, following the specification in the file that "1 = Male, 0 = Female". The same is done for APOE-4 carrier, following that "1 = APOE4 carrier, 0 = APOE4 non-carrier". Given that anyone who doesn't develop MCI will not have age_at_onset, we exclude individuals for whom that value is null to filter to participants who meet inclusion crtieria. 

* **Recruietment:** A total of `r nrow(mci_baseline_all)` participants were recruited, of which `r nrow(mci_baseline)` (`r (nrow(mci_baseline)/nrow(mci_baseline_all) * 100) |> round(2)`%) develop MCI. 
* **Age:** The average age at enrollment of recruited participants is `r mci_baseline_all |> pull(current_age) |> mean() |> round(2)` and of eligible participants is `r mci_baseline |> pull(current_age) |> mean() |> round(2)`. The average age at onset is `r mci_baseline |> pull(age_at_onset) |> mean() |> round(2)`
* **Gender** Of recruited participants, `r (nrow(filter(mci_baseline_all, sex == "Male"))/nrow(mci_baseline_all)*100) |> round(2)`% are male and `r (nrow(filter(mci_baseline_all, sex == "Female"))/nrow(mci_baseline_all)*100) |> round(2)`% are female. 
* **APOE4 Carrier Status** Of recruited participants, `r (nrow(filter(mci_baseline_all, apoe4 == "carrier"))/nrow(mci_baseline_all)*100) |> round(2)`% are carriers and `r (nrow(filter(mci_baseline_all, apoe4 == "non_carrier"))/nrow(mci_baseline_all)*100) |> round(2)`% are not carriers

## Biomarker data 
```{r load_mci_biomarker, warning = FALSE}
mci_amyloid =
  read_csv('./data/data_mci/mci_amyloid.csv', skip = 1) |>
  janitor::clean_names() |>
  mutate(baseline = as.numeric(baseline)) |>  
  mutate(time_2 = as.numeric(time_2)) |>
  mutate(time_4 = as.numeric(time_4)) |>
  mutate(time_6 = as.numeric(time_6)) |>
  mutate(time_8 = as.numeric(time_8))
#skimr::skim(mci_amyloid)
```

The dataset details the ratio of amyloid beta in participants observed at baseline and 4 follow-up time points. The average ratio is `r filter(mci_amyloid, baseline > 0) |> pull(baseline) |> mean() |> round(2)` at baseline, `r filter(mci_amyloid, time_2 > 0) |> pull(time_2) |> mean() |> round(2)` at two years, `r filter(mci_amyloid, time_4 > 0) |> pull(time_4) |> mean() |> round(2)` at four years, `r filter(mci_amyloid, time_6 > 0) |> pull(time_6) |> mean() |> round(2)` at six years, `r filter(mci_amyloid, time_8 > 0) |> pull(time_8) |> mean() |> round(2)` at eight years. 

There are `r sum(is.na(mci_amyloid$baseline))` baseline values missing, `r sum(is.na(mci_amyloid$time_2))` year 2 values missing, `r sum(is.na(mci_amyloid$time_4))` year 4 values missing,`r sum(is.na(mci_amyloid$time_6))` year 6 values missing, and `r sum(is.na(mci_amyloid$time_8))` year 8 values missing. 


## Participant overlap

### Exploring patients only in one dataset 
Check whether some participants appear in only the baseline or amyloid datasets, and comment on your findings. Combine the demographic and biomarker datasets so that only participants who appear in both datasets are retained, and briefly describe the resulting dataset; export the result as a CSV to your data directory.

```{r mci_overlap}
mci_baseline_all = mci_baseline_all |> mutate(name = "baseline")
mci_amyloid = 
  mci_amyloid |> 
  mutate(name = "amyloid") |> 
  rename(id = study_id)

mci_all =
  full_join(mci_baseline_all, mci_amyloid, by = "id")
#mci_all
#skimr::skim(mci_all)
```


`r nrow(mci_baseline_all)` participants were recruited, `r nrow(mci_baseline)` were eligible for inclusion. `r nrow(mci_amyloid)` have biomarker data recorded. There are `r mci_all |> filter(is.na(name.x), !is.na(name.y)) |> nrow()` patients with no baseline demographics but with biomarker data. There are `r mci_all |> filter(!is.na(name.x), is.na(name.y)) |> nrow()` patients with  baseline demographics but no biomarker data. Presumably study recruitment and retention is challenging, and so I would expect biomarker data to be missing as it requires follow-up. However, it the inverse (that there are participants with biomarker missing baseline demographics)
is more surprising. 

### Generating CSV of Overlap
```{r overlap_to_csv}
mci_overlap =
  inner_join(mci_baseline_all, mci_amyloid, by = "id") |> 
  select(-name.x, -name.y)
#mci_overlap
#skimr::skim(mci_overlap)

write_csv(mci_overlap, "./data/data_mci/mci_overlap.csv")
```

There are a total of `r nrow(mci_overlap)` patients with both baseline and biomarker data. They have an average age at enrollment of `r mci_overlap |> pull(current_age) |> mean()|> round(2)`. There are `r mci_overlap |> filter(!is.na(age_at_onset)) |> nrow() ` of these patients who develop MCI. 


