p8105_hw2_khs2318
================
Kayla Schiffer-Kane
2023-10-04

- [Problem 1](#problem-1)
  - [Clean pols_month](#clean-pols_month)
  - [Clean snp](#clean-snp)
  - [Clean Unemployment](#clean-unemployment)
  - [Merge all data](#merge-all-data)
- [Problem 2](#problem-2)
  - [Load and Clean Data](#load-and-clean-data)
  - [Calculate homes_powered](#calculate-homes_powered)
  - [Remaining](#remaining)

``` r
library(tidyverse)
library(readxl)
```

# Problem 1

Dataset is FiveThirtyEight data

## Clean pols_month

Clean the data in pols-month.csv. Use `separate()` to break up the
variable mon into integer variables `year`, `month`, and `day`; replace
`month` number with month name; create a `president` variable taking
values `gop` and `dem`, and remove `prez_dem` and `prez_gop`; and remove
the `day` variable.

``` r
pols_month =
  read_csv('./data/fivethirtyeight_datasets/pols-month.csv') |>
  separate(mon, c("year","month","day")) |>
  mutate(month = month.name[as.numeric(month)]) |>
  mutate(president = recode(prez_dem, "1" = "dem", "0" = "gop")) |>
  select(-prez_dem,-prez_gop, - day)
  
head(pols_month)
```

    ## # A tibble: 6 × 9
    ##   year  month    gov_gop sen_gop rep_gop gov_dem sen_dem rep_dem president
    ##   <chr> <chr>      <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl> <chr>    
    ## 1 1947  January       23      51     253      23      45     198 dem      
    ## 2 1947  February      23      51     253      23      45     198 dem      
    ## 3 1947  March         23      51     253      23      45     198 dem      
    ## 4 1947  April         23      51     253      23      45     198 dem      
    ## 5 1947  May           23      51     253      23      45     198 dem      
    ## 6 1947  June          23      51     253      23      45     198 dem

## Clean snp

Second, clean the data in snp.csv using a similar process to the above.
For consistency across datasets, arrange according to year and month,
and organize so that year and month are the leading columns.

``` r
snp =
  read_csv('./data/fivethirtyeight_datasets/snp.csv') |>
  separate(date, c("month","day","year"), sep = '/') |>
  mutate(month = month.name[as.numeric(month)]) |>
  mutate(year = if_else(year > 15, paste0("19",year), paste0("20",year))) |> 
  #arrange(year, month) |>
  select(year,month,close)
tail(snp)
```

    ## # A tibble: 6 × 3
    ##   year  month    close
    ##   <chr> <chr>    <dbl>
    ## 1 1950  June      17.7
    ## 2 1950  May       18.8
    ## 3 1950  April     18.0
    ## 4 1950  March     17.3
    ## 5 1950  February  17.2
    ## 6 1950  January   17.0

## Clean Unemployment

Third, tidy the unemployment data so that it can be merged with the
previous datasets. This process will involve switching from “wide” to
“long” format; ensuring that key variables have the same name; and
ensuring that key variables take the same values.

``` r
unemployment =
  read_csv('./data/fivethirtyeight_datasets/unemployment.csv') |> 
  pivot_longer(Jan:Dec,
               names_to = "month",
               values_to = "percentage") |>
  janitor::clean_names() |>
  mutate(month = month.name[match(month, month.abb)]) |> # Jan -> January 
  mutate(year = as.character(year))
unemployment
```

    ## # A tibble: 816 × 3
    ##    year  month     percentage
    ##    <chr> <chr>          <dbl>
    ##  1 1948  January          3.4
    ##  2 1948  February         3.8
    ##  3 1948  March            4  
    ##  4 1948  April            3.9
    ##  5 1948  May              3.5
    ##  6 1948  June             3.6
    ##  7 1948  July             3.6
    ##  8 1948  August           3.9
    ##  9 1948  September        3.8
    ## 10 1948  October          3.7
    ## # ℹ 806 more rows

## Merge all data

Required casting year in unemployment to character

``` r
data = 
  left_join(pols_month, snp) |>
  left_join(x = _, y = unemployment)
```

The resulting dataset has 822 rows and 11 columns.

- Pols_month has 822 rows, and we created `president` which tells us if
  the president was a gop/dem in a given year. This column was created
  from a combination of `prez_gop` and `prez_dem`, which I tested to
  make sure are truly mutually exclusive. Years include 1947 to 2015
- SNP has 787, with data from 1950 to 2015. Average close price for
  these years is 474.8887404
- Unemployment has unemployment rates from 1948 to 2015. Average
  unemployment for these years is 5.83
- Because the years don’t overlap exactly, we’ll miss some data for
  certain years - hence the “NAs” in the merged dataset - 36 values are
  missing SNP close price `close`, and 12 are missing unemployment rates
  `percentage`.

# Problem 2

## Load and Clean Data

Read and clean the Mr. Trash Wheel sheet:

- specify the sheet in the Excel file and to omit non-data entries (rows
  with notes / figures; columns containing notes) using arguments in
  read_excel

- use reasonable variable names

- omit rows that do not include dumpster-specific data

- The last row contains sums of the previous so should be excluded. This
  is the only row where date is missing, so excluding it by filtering
  out where Month is null.

``` r
trashwheel_data = read_excel("./data/202309 Trash Wheel Collection Data.xlsx",
                             sheet = "Mr. Trash Wheel",
                             skip = 1,
                             range = cell_cols("A:N")) |>
  filter(!is.na(Month)) |> 
  janitor::clean_names()
skimr::skim(trashwheel_data)
```

|                                                  |                 |
|:-------------------------------------------------|:----------------|
| Name                                             | trashwheel_data |
| Number of rows                                   | 584             |
| Number of columns                                | 14              |
| \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_   |                 |
| Column type frequency:                           |                 |
| character                                        | 2               |
| numeric                                          | 11              |
| POSIXct                                          | 1               |
| \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_ |                 |
| Group variables                                  | None            |

Data summary

**Variable type: character**

| skim_variable | n_missing | complete_rate | min | max | empty | n_unique | whitespace |
|:--------------|----------:|--------------:|----:|----:|------:|---------:|-----------:|
| month         |         0 |             1 |   3 |   9 |     0 |       13 |          0 |
| year          |         0 |             1 |   4 |   4 |     0 |       10 |          0 |

**Variable type: numeric**

| skim_variable      | n_missing | complete_rate |     mean |       sd |     p0 |     p25 |    p50 |      p75 |      p100 | hist  |
|:-------------------|----------:|--------------:|---------:|---------:|-------:|--------:|-------:|---------:|----------:|:------|
| dumpster           |         0 |             1 |   292.50 |   168.73 |   1.00 |  146.75 |  292.5 |   438.25 |    584.00 | ▇▇▇▇▇ |
| weight_tons        |         0 |             1 |     3.21 |     0.75 |   0.78 |    2.72 |    3.2 |     3.73 |      5.62 | ▁▃▇▃▁ |
| volume_cubic_yards |         0 |             1 |    15.30 |     1.36 |   7.00 |   15.00 |   15.0 |    15.00 |     20.00 | ▁▁▁▇▁ |
| plastic_bottles    |         0 |             1 |  1979.19 |  1060.37 | 210.00 | 1000.00 | 1900.0 |  2780.00 |   5960.00 | ▇▇▆▂▁ |
| polystyrene        |         0 |             1 |  1558.13 |  1230.65 |  48.00 |  555.00 | 1160.0 |  2400.00 |   6540.00 | ▇▃▂▁▁ |
| cigarette_butts    |         0 |             1 | 19832.57 | 29543.43 | 900.00 | 3900.00 | 6500.0 | 24000.00 | 310000.00 | ▇▁▁▁▁ |
| glass_bottles      |         0 |             1 |    21.62 |    16.05 |   0.00 |   10.00 |   18.0 |    30.00 |    110.00 | ▇▃▁▁▁ |
| plastic_bags       |         0 |             1 |   916.76 |   839.01 |  24.00 |  290.00 |  635.0 |  1242.00 |   3750.00 | ▇▃▂▁▁ |
| wrappers           |         0 |             1 |  1416.37 |   902.36 | 180.00 |  750.00 | 1100.0 |  1980.00 |   5085.00 | ▇▅▂▁▁ |
| sports_balls       |         0 |             1 |    13.17 |     9.56 |   0.00 |    6.00 |   11.0 |    18.25 |     56.00 | ▇▆▂▁▁ |
| homes_powered      |         0 |             1 |    47.28 |    20.48 |   0.00 |   40.63 |   51.5 |    60.33 |     93.67 | ▂▂▇▆▁ |

**Variable type: POSIXct**

| skim_variable | n_missing | complete_rate | min        | max        | median     | n_unique |
|:--------------|----------:|--------------:|:-----------|:-----------|:-----------|---------:|
| date          |         0 |             1 | 1900-01-20 | 2023-06-29 | 2018-09-01 |      356 |

``` r
trashwheel_data
```

    ## # A tibble: 584 × 14
    ##    dumpster month year  date                weight_tons volume_cubic_yards
    ##       <dbl> <chr> <chr> <dttm>                    <dbl>              <dbl>
    ##  1        1 May   2014  2014-05-16 00:00:00        4.31                 18
    ##  2        2 May   2014  2014-05-16 00:00:00        2.74                 13
    ##  3        3 May   2014  2014-05-16 00:00:00        3.45                 15
    ##  4        4 May   2014  2014-05-17 00:00:00        3.1                  15
    ##  5        5 May   2014  2014-05-17 00:00:00        4.06                 18
    ##  6        6 May   2014  2014-05-20 00:00:00        2.71                 13
    ##  7        7 May   2014  2014-05-21 00:00:00        1.91                  8
    ##  8        8 May   2014  2014-05-28 00:00:00        3.7                  16
    ##  9        9 June  2014  2014-06-05 00:00:00        2.52                 14
    ## 10       10 June  2014  2014-06-11 00:00:00        3.76                 18
    ## # ℹ 574 more rows
    ## # ℹ 8 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, glass_bottles <dbl>, plastic_bags <dbl>,
    ## #   wrappers <dbl>, sports_balls <dbl>, homes_powered <dbl>

## Calculate homes_powered

The data include a column for the (approximate) number of homes powered.
This calculation is described in the `Homes powered note`, but not
applied to every row in the dataset. Update the data to include a new
`homes_powered` variable based on this calculation.

- From excel: Homes Powered - Each ton of trash equates to on average
  500 kilowatts of electricity. An average household will use 30
  kilowatts per day.

``` r
kw_per_ton = 500
kw_per_house = 30
trashwheel_data = trashwheel_data |>
  rename(homes_powered_orig = homes_powered) |>
  mutate(homes_powered = (weight_tons * kw_per_ton / kw_per_house))
```

*Checking* to see if the calculation looks similar to the original
`homes` column. Using only where the homes_powered from original dataset
was calculated, the average number of homes powered is 53.31 compared to
our calculation, 53.51. These are fairly equivalent.

## Remaining

Use a similar process to import, clean, and organize the data for
Professor Trash Wheel and Gwynnda, and combine these with the Mr. Trash
Wheel dataset to produce a single tidy dataset. To keep track of which
Trash Wheel is which, you may need to add an additional variable to all
datasets before combining.

Write a paragraph about these data; you are encouraged to use inline R.
Be sure to note the number of observations in the resulting dataset, and
give examples of key variables. For available data, what was the total
weight of trash collected by Professor Trash Wheel? What was the total
number of cigarette butts collected by Gwynnda in July of 2021?
