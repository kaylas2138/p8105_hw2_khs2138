p8105_hw2_khs2318
================
Kayla Schiffer-Kane
2023-10-04

- [Problem 1](#problem-1)
  - [Clean pols_month](#clean-pols_month)
  - [Clean snp](#clean-snp)
  - [Clean Unemployment](#clean-unemployment)
  - [Merge all data](#merge-all-data)
- [Problem 2](#problem-2)
  - [Load and Clean Data](#load-and-clean-data)
  - [Calculate homes_powered](#calculate-homes_powered)
  - [Professor and Gwynnda Trash
    Wheels](#professor-and-gwynnda-trash-wheels)
    - [Load and Clean Professor Trash
      Wheel](#load-and-clean-professor-trash-wheel)
    - [Load and Clean Gwynnda Trash
      Wheel](#load-and-clean-gwynnda-trash-wheel)
    - [Combine Data Sets](#combine-data-sets)
  - [Summary of Data](#summary-of-data)

``` r
library(tidyverse)
library(readxl)
```

# Problem 1

Dataset is FiveThirtyEight data

## Clean pols_month

Clean the data in pols-month.csv. Use `separate()` to break up the
variable mon into integer variables `year`, `month`, and `day`; replace
`month` number with month name; create a `president` variable taking
values `gop` and `dem`, and remove `prez_dem` and `prez_gop`; and remove
the `day` variable.

``` r
pols_month =
  read_csv('./data/fivethirtyeight_datasets/pols-month.csv') |>
  separate(mon, c("year","month","day")) |>
  mutate(month = month.name[as.numeric(month)]) |>
  mutate(president = recode(prez_dem, "1" = "dem", "0" = "gop")) |>
  select(-prez_dem,-prez_gop, - day)
  
head(pols_month)
```

    ## # A tibble: 6 × 9
    ##   year  month    gov_gop sen_gop rep_gop gov_dem sen_dem rep_dem president
    ##   <chr> <chr>      <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl> <chr>    
    ## 1 1947  January       23      51     253      23      45     198 dem      
    ## 2 1947  February      23      51     253      23      45     198 dem      
    ## 3 1947  March         23      51     253      23      45     198 dem      
    ## 4 1947  April         23      51     253      23      45     198 dem      
    ## 5 1947  May           23      51     253      23      45     198 dem      
    ## 6 1947  June          23      51     253      23      45     198 dem

## Clean snp

Second, clean the data in snp.csv using a similar process to the above.
For consistency across datasets, arrange according to year and month,
and organize so that year and month are the leading columns.

``` r
snp =
  read_csv('./data/fivethirtyeight_datasets/snp.csv') |>
  separate(date, c("month","day","year"), sep = '/') |>
  mutate(month = month.name[as.numeric(month)]) |>
  mutate(year = if_else(year > 15, paste0("19",year), paste0("20",year))) |> 
  #arrange(year, month) |>
  select(year,month,close)
tail(snp)
```

    ## # A tibble: 6 × 3
    ##   year  month    close
    ##   <chr> <chr>    <dbl>
    ## 1 1950  June      17.7
    ## 2 1950  May       18.8
    ## 3 1950  April     18.0
    ## 4 1950  March     17.3
    ## 5 1950  February  17.2
    ## 6 1950  January   17.0

## Clean Unemployment

Third, tidy the unemployment data so that it can be merged with the
previous datasets. This process will involve switching from “wide” to
“long” format; ensuring that key variables have the same name; and
ensuring that key variables take the same values.

``` r
unemployment =
  read_csv('./data/fivethirtyeight_datasets/unemployment.csv') |> 
  pivot_longer(Jan:Dec,
               names_to = "month",
               values_to = "percentage") |>
  janitor::clean_names() |>
  mutate(month = month.name[match(month, month.abb)]) |> # Jan -> January 
  mutate(year = as.character(year))
unemployment
```

    ## # A tibble: 816 × 3
    ##    year  month     percentage
    ##    <chr> <chr>          <dbl>
    ##  1 1948  January          3.4
    ##  2 1948  February         3.8
    ##  3 1948  March            4  
    ##  4 1948  April            3.9
    ##  5 1948  May              3.5
    ##  6 1948  June             3.6
    ##  7 1948  July             3.6
    ##  8 1948  August           3.9
    ##  9 1948  September        3.8
    ## 10 1948  October          3.7
    ## # ℹ 806 more rows

## Merge all data

Required casting year in unemployment to character

``` r
data = 
  left_join(pols_month, snp) |>
  left_join(x = _, y = unemployment)
```

The resulting dataset has 822 rows and 11 columns.

- Pols_month has 822 rows, and we created `president` which tells us if
  the president was a gop/dem in a given year. This column was created
  from a combination of `prez_gop` and `prez_dem`, which I tested to
  make sure are truly mutually exclusive. Years include 1947 to 2015
- SNP has 787, with data from 1950 to 2015. Average close price for
  these years is 474.8887404
- Unemployment has unemployment rates from 1948 to 2015. Average
  unemployment for these years is 5.83
- Because the years don’t overlap exactly, we’ll miss some data for
  certain years - hence the “NAs” in the merged dataset - 36 values are
  missing SNP close price `close`, and 12 are missing unemployment rates
  `percentage`.

# Problem 2

## Load and Clean Data

Read and clean the Mr. Trash Wheel sheet:

- specify the sheet in the Excel file and to omit non-data entries (rows
  with notes / figures; columns containing notes) using arguments in
  read_excel

- use reasonable variable names

- omit rows that do not include dumpster-specific data

- The last row contains sums of the previous so should be excluded. This
  is the only row where date is missing, so excluding it by filtering
  out where Month is null.

``` r
mr_data = read_excel("./data/202309 Trash Wheel Collection Data.xlsx",
                             sheet = "Mr. Trash Wheel",
                             skip = 1,
                             range = cell_cols("A:N")) |>
  filter(!is.na(Month)) |> 
  janitor::clean_names() |> 
  mutate(name = "mr_trash_wheel") |> 
  mutate(year = as.numeric(year))
#skimr::skim(mr_data)

mr_data
```

    ## # A tibble: 584 × 15
    ##    dumpster month  year date                weight_tons volume_cubic_yards
    ##       <dbl> <chr> <dbl> <dttm>                    <dbl>              <dbl>
    ##  1        1 May    2014 2014-05-16 00:00:00        4.31                 18
    ##  2        2 May    2014 2014-05-16 00:00:00        2.74                 13
    ##  3        3 May    2014 2014-05-16 00:00:00        3.45                 15
    ##  4        4 May    2014 2014-05-17 00:00:00        3.1                  15
    ##  5        5 May    2014 2014-05-17 00:00:00        4.06                 18
    ##  6        6 May    2014 2014-05-20 00:00:00        2.71                 13
    ##  7        7 May    2014 2014-05-21 00:00:00        1.91                  8
    ##  8        8 May    2014 2014-05-28 00:00:00        3.7                  16
    ##  9        9 June   2014 2014-06-05 00:00:00        2.52                 14
    ## 10       10 June   2014 2014-06-11 00:00:00        3.76                 18
    ## # ℹ 574 more rows
    ## # ℹ 9 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, glass_bottles <dbl>, plastic_bags <dbl>,
    ## #   wrappers <dbl>, sports_balls <dbl>, homes_powered <dbl>, name <chr>

## Calculate homes_powered

The data include a column for the (approximate) number of homes powered.
This calculation is described in the `Homes powered note`, but not
applied to every row in the dataset. Update the data to include a new
`homes_powered` variable based on this calculation.

- From excel: Homes Powered - Each ton of trash equates to on average
  500 kilowatts of electricity. An average household will use 30
  kilowatts per day.

``` r
kw_per_ton = 500
kw_per_house = 30
mr_data = mr_data |>
  rename(homes_powered_orig = homes_powered) |>
  mutate(homes_powered = (weight_tons * kw_per_ton / kw_per_house))
```

**Checking** to see if the calculation looks similar to the original
`homes` column. Using only where the homes_powered from original dataset
was calculated, the average number of homes powered is 53.31 compared to
our calculation, 53.51. These are fairly equivalent.

## Professor and Gwynnda Trash Wheels

Use a similar process to import, clean, and organize the data for
Professor Trash Wheel and Gwynnda, and combine these with the Mr. Trash
Wheel dataset to produce a single tidy dataset. To keep track of which
Trash Wheel is which, you may need to add an additional variable to all
datasets before combining.

### Load and Clean Professor Trash Wheel

``` r
prof_data = read_excel("./data/202309 Trash Wheel Collection Data.xlsx",
                             sheet = "Professor Trash Wheel",
                             skip = 1,
                             range = cell_cols("A:M")) |>
  filter(!is.na(Month)) |> 
  janitor::clean_names() |> 
  mutate(homes_powered = (weight_tons * kw_per_ton / kw_per_house)) |> 
  mutate(name = "professor_trash_wheel")
#skimr::skim(prof_data)

prof_data
```

    ## # A tibble: 106 × 14
    ##    dumpster month     year date                weight_tons volume_cubic_yards
    ##       <dbl> <chr>    <dbl> <dttm>                    <dbl>              <dbl>
    ##  1        1 January   2017 2017-01-02 00:00:00        1.79                 15
    ##  2        2 January   2017 2017-01-30 00:00:00        1.58                 15
    ##  3        3 February  2017 2017-02-26 00:00:00        2.32                 18
    ##  4        4 February  2017 2017-02-26 00:00:00        3.72                 15
    ##  5        5 February  2017 2017-02-28 00:00:00        1.45                 15
    ##  6        6 March     2017 2017-03-30 00:00:00        1.71                 15
    ##  7        7 April     2017 2017-04-01 00:00:00        1.82                 15
    ##  8        8 April     2017 2017-04-20 00:00:00        2.37                 15
    ##  9        9 May       2017 2017-05-10 00:00:00        2.64                 15
    ## 10       10 May       2017 2017-05-26 00:00:00        2.78                 15
    ## # ℹ 96 more rows
    ## # ℹ 8 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, glass_bottles <dbl>, plastic_bags <dbl>,
    ## #   wrappers <dbl>, homes_powered <dbl>, name <chr>

### Load and Clean Gwynnda Trash Wheel

``` r
gwyn_data = read_excel("./data/202309 Trash Wheel Collection Data.xlsx",
                             sheet = "Gwynnda Trash Wheel",
                             skip = 1,
                             range = cell_cols("A:L")) |>
  filter(!is.na(Month)) |> 
  janitor::clean_names() |> 
  mutate(homes_powered = (weight_tons * kw_per_ton / kw_per_house)) |> 
  mutate(name = "gwynnda_trash_wheel")
#skimr::skim(gwyn_data)
gwyn_data
```

    ## # A tibble: 155 × 13
    ##    dumpster month   year date                weight_tons volume_cubic_yards
    ##       <dbl> <chr>  <dbl> <dttm>                    <dbl>              <dbl>
    ##  1        1 July    2021 2021-07-03 00:00:00        0.93                 15
    ##  2        2 July    2021 2021-07-07 00:00:00        2.26                 15
    ##  3        3 July    2021 2021-07-07 00:00:00        1.62                 15
    ##  4        4 July    2021 2021-07-16 00:00:00        1.76                 15
    ##  5        5 July    2021 2021-07-30 00:00:00        1.53                 15
    ##  6        6 August  2021 2021-08-11 00:00:00        2.06                 15
    ##  7        7 August  2021 2021-08-14 00:00:00        1.9                  15
    ##  8        8 August  2021 2021-08-16 00:00:00        2.16                 15
    ##  9        9 August  2021 2021-08-16 00:00:00        2.6                  15
    ## 10       10 August  2021 2021-08-17 00:00:00        3.21                 15
    ## # ℹ 145 more rows
    ## # ℹ 7 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, plastic_bags <dbl>, wrappers <dbl>,
    ## #   homes_powered <dbl>, name <chr>

### Combine Data Sets

``` r
trash_tidy = 
  bind_rows(mr_data, prof_data, gwyn_data) |>
  select(name, everything(), -homes_powered_orig)

head(trash_tidy)
```

    ## # A tibble: 6 × 15
    ##   name   dumpster month  year date                weight_tons volume_cubic_yards
    ##   <chr>     <dbl> <chr> <dbl> <dttm>                    <dbl>              <dbl>
    ## 1 mr_tr…        1 May    2014 2014-05-16 00:00:00        4.31                 18
    ## 2 mr_tr…        2 May    2014 2014-05-16 00:00:00        2.74                 13
    ## 3 mr_tr…        3 May    2014 2014-05-16 00:00:00        3.45                 15
    ## 4 mr_tr…        4 May    2014 2014-05-17 00:00:00        3.1                  15
    ## 5 mr_tr…        5 May    2014 2014-05-17 00:00:00        4.06                 18
    ## 6 mr_tr…        6 May    2014 2014-05-20 00:00:00        2.71                 13
    ## # ℹ 8 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, glass_bottles <dbl>, plastic_bags <dbl>,
    ## #   wrappers <dbl>, sports_balls <dbl>, homes_powered <dbl>

``` r
unique(trash_tidy$name)
```

    ## [1] "mr_trash_wheel"        "professor_trash_wheel" "gwynnda_trash_wheel"

## Summary of Data

There are 584 observations from Mr. Trash Wheel, 106 observations from
Professor Trash Wheel, and 155 observations from Gwynnda Trash Wheel.

- Gwynndata is missing `sports` and `glass_bottles`. `wrappers` values
  are missing for many of the rows. There is also one dumpster number
  listed twice with different data (#21)

- Professor Trash Wheel doesn’t have `sports` column. Professor Trash
  Wheel has one row missing many of the variables

- These match the combined dataset counts: 584, 106, and 155,
  respectively.

- The average number of estimated homes powered overall is 50.16. For
  each trash wheel, the average is 53.51 for Mr. Trash Wheel, 34 for
  Professor Trash Wheel, and 48.56 for Gwynnda Trash Wheel,

- The total weight of trash collected by professor trash_wheel is 216.26
  tons.

- The total number of cigarette butts collected by Gwynnda in July 2021
  is 1.63^{4}
