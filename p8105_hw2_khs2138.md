p8105_hw2_khs2318
================
Kayla Schiffer-Kane
2023-10-04

- [Problem 1](#problem-1)
  - [Clean pols_month](#clean-pols_month)
  - [Clean snp](#clean-snp)
  - [Clean Unemployment](#clean-unemployment)
  - [Merge all data](#merge-all-data)
- [Problem 2](#problem-2)
  - [Load and Clean Data](#load-and-clean-data)
  - [Calculate homes_powered](#calculate-homes_powered)
  - [Professor and Gwynnda Trash
    Wheels](#professor-and-gwynnda-trash-wheels)
    - [Load and Clean Professor Trash
      Wheel](#load-and-clean-professor-trash-wheel)
    - [Load and Clean Gwynnda Trash
      Wheel](#load-and-clean-gwynnda-trash-wheel)
    - [Combine Data Sets](#combine-data-sets)
  - [Summary of Data](#summary-of-data)
- [Problem 3](#problem-3)
  - [Baseline Demographics](#baseline-demographics)
  - [Biomarker data](#biomarker-data)
  - [Participant overlap](#participant-overlap)
    - [Exploring patients only in one
      dataset](#exploring-patients-only-in-one-dataset)
    - [Generating CSV of Overlap](#generating-csv-of-overlap)

``` r
library(tidyverse)
library(readxl)
```

# Problem 1

Dataset is FiveThirtyEight data

## Clean pols_month

Clean the data in pols-month.csv. Use `separate()` to break up the
variable mon into integer variables `year`, `month`, and `day`; replace
`month` number with month name; create a `president` variable taking
values `gop` and `dem`, and remove `prez_dem` and `prez_gop`; and remove
the `day` variable.

``` r
pols_month =
  read_csv('./data/fivethirtyeight_datasets/pols-month.csv') |>
  separate(mon, c("year","month","day")) |>
  mutate(month = month.name[as.numeric(month)]) |>
  mutate(president = recode(prez_dem, "1" = "dem", "0" = "gop")) |>
  select(-prez_dem,-prez_gop, - day)
  
#head(pols_month)
```

## Clean snp

Second, clean the data in snp.csv using a similar process to the above.
For consistency across datasets, arrange according to year and month,
and organize so that year and month are the leading columns.

``` r
snp =
  read_csv('./data/fivethirtyeight_datasets/snp.csv') |>
  separate(date, c("month","day","year"), sep = '/') |>
  mutate(month = month.name[as.numeric(month)]) |>
  mutate(year = if_else(year > 15, paste0("19",year), paste0("20",year))) |> 
  #arrange(year, month) |>
  select(year,month,close)
#tail(snp)
```

## Clean Unemployment

Third, tidy the unemployment data so that it can be merged with the
previous datasets. This process will involve switching from “wide” to
“long” format; ensuring that key variables have the same name; and
ensuring that key variables take the same values.

``` r
unemployment =
  read_csv('./data/fivethirtyeight_datasets/unemployment.csv') |> 
  pivot_longer(Jan:Dec,
               names_to = "month",
               values_to = "percentage") |>
  janitor::clean_names() |>
  mutate(month = month.name[match(month, month.abb)]) |> # Jan -> January 
  mutate(year = as.character(year))
#unemployment
```

## Merge all data

Required casting year in unemployment to character

``` r
data = 
  left_join(pols_month, snp) |>
  left_join(x = _, y = unemployment)
```

The resulting dataset has 822 rows and 11 columns.

- Pols_month has 822 rows, and we created `president` which tells us if
  the president was a gop/dem in a given year. This column was created
  from a combination of `prez_gop` and `prez_dem`, which I tested to
  make sure are truly mutually exclusive. Years include 1947 to 2015
- SNP has 787, with data from 1950 to 2015. Average close price for
  these years is 474.8887404
- Unemployment has unemployment rates from 1948 to 2015. Average
  unemployment for these years is 5.83
- Because the years don’t overlap exactly, we’ll miss some data for
  certain years - hence the “NAs” in the merged dataset - 36 values are
  missing SNP close price `close`, and 12 are missing unemployment rates
  `percentage`.

# Problem 2

## Load and Clean Data

Read and clean the Mr. Trash Wheel sheet:

- specify the sheet in the Excel file and to omit non-data entries (rows
  with notes / figures; columns containing notes) using arguments in
  read_excel

- use reasonable variable names

- omit rows that do not include dumpster-specific data

- The last row contains sums of the previous so should be excluded. This
  is the only row where date is missing, so excluding it by filtering
  out where Month is null.

``` r
mr_data = read_excel("./data/202309 Trash Wheel Collection Data.xlsx",
                             sheet = "Mr. Trash Wheel",
                             skip = 1,
                             range = cell_cols("A:N")) |>
  filter(!is.na(Month)) |> 
  janitor::clean_names() |> 
  mutate(name = "mr_trash_wheel") |> 
  mutate(year = as.numeric(year))
#skimr::skim(mr_data)

#mr_data
```

## Calculate homes_powered

The data include a column for the (approximate) number of homes powered.
This calculation is described in the `Homes powered note`, but not
applied to every row in the dataset. Update the data to include a new
`homes_powered` variable based on this calculation.

- From excel: Homes Powered - Each ton of trash equates to on average
  500 kilowatts of electricity. An average household will use 30
  kilowatts per day.

``` r
kw_per_ton = 500
kw_per_house = 30
mr_data = mr_data |>
  rename(homes_powered_orig = homes_powered) |>
  mutate(homes_powered = (weight_tons * kw_per_ton / kw_per_house))
```

**Checking** to see if the calculation looks similar to the original
`homes` column. Using only where the homes_powered from original dataset
was calculated, the average number of homes powered is 53.31 compared to
our calculation, 53.51. These are fairly equivalent.

## Professor and Gwynnda Trash Wheels

Use a similar process to import, clean, and organize the data for
Professor Trash Wheel and Gwynnda, and combine these with the Mr. Trash
Wheel dataset to produce a single tidy dataset. To keep track of which
Trash Wheel is which, you may need to add an additional variable to all
datasets before combining.

### Load and Clean Professor Trash Wheel

``` r
prof_data = read_excel("./data/202309 Trash Wheel Collection Data.xlsx",
                             sheet = "Professor Trash Wheel",
                             skip = 1,
                             range = cell_cols("A:M")) |>
  filter(!is.na(Month)) |> 
  janitor::clean_names() |> 
  mutate(homes_powered = (weight_tons * kw_per_ton / kw_per_house)) |> 
  mutate(name = "professor_trash_wheel")
#skimr::skim(prof_data)

#prof_data
```

### Load and Clean Gwynnda Trash Wheel

``` r
gwyn_data = read_excel("./data/202309 Trash Wheel Collection Data.xlsx",
                             sheet = "Gwynnda Trash Wheel",
                             skip = 1,
                             range = cell_cols("A:L")) |>
  filter(!is.na(Month)) |> 
  janitor::clean_names() |> 
  mutate(homes_powered = (weight_tons * kw_per_ton / kw_per_house)) |> 
  mutate(name = "gwynnda_trash_wheel")
#skimr::skim(gwyn_data)
#gwyn_data
```

### Combine Data Sets

``` r
trash_tidy = 
  bind_rows(mr_data, prof_data, gwyn_data) |>
  select(name, everything(), -homes_powered_orig)

#head(trash_tidy)
#unique(trash_tidy$name)
```

## Summary of Data

There are 584 observations from Mr. Trash Wheel, 106 observations from
Professor Trash Wheel, and 155 observations from Gwynnda Trash Wheel.

- Gwynndata is missing `sports` and `glass_bottles`. `wrappers` values
  are missing for many of the rows. There is also one dumpster number
  listed twice with different data (#21)

- Professor Trash Wheel doesn’t have `sports` column. Professor Trash
  Wheel has one row missing many of the variables

- These match the combined dataset counts: 584, 106, and 155,
  respectively.

- The average number of estimated homes powered overall is 50.16. For
  each trash wheel, the average is 53.51 for Mr. Trash Wheel, 34 for
  Professor Trash Wheel, and 48.56 for Gwynnda Trash Wheel,

- The total weight of trash collected by professor trash_wheel is 216.26
  tons.

- The total number of cigarette butts collected by Gwynnda in July 2021
  is 1.63^{4}

# Problem 3

## Baseline Demographics

Import, clean, and tidy the dataset of baseline demographics. \* Ensure
that sex and APOE4 carrier status are appropriate encoded (i.e. not
numeric) \* Remove any participants who do not meet the stated inclusion
criteria (i.e. no MCI at baseline).

``` r
mci_baseline_all =
  read_csv('./data/data_mci/MCI_baseline.csv', skip = 1) |>
  janitor::clean_names() |>
  mutate(age_at_onset = as.numeric(age_at_onset)) |> 
  mutate(sex = recode(sex, "0" = "Female", "1" = "Male")) |>
  mutate(sex = as.factor(sex)) |>
  mutate(apoe4 = recode(apoe4, "0" = "non_carrier", "1" = "carrier")) |>
  mutate(apoe4 = as.factor(apoe4))

mci_baseline = mci_baseline_all |>
  filter(!is.na(age_at_onset))

#skimr::skim(mci_baseline)
#head(mci_baseline)
```

Age at onset is converted to numeric, as it is stored as a character.
Sex is converted from binary to a factor, following the specification in
the file that “1 = Male, 0 = Female”. The same is done for APOE-4
carrier, following that “1 = APOE4 carrier, 0 = APOE4 non-carrier”.
Given that anyone who doesn’t develop MCI will not have age_at_onset, we
exclude individuals for whom that value is null to filter to
participants who meet inclusion crtieria.

- **Recruietment:** A total of 483 participants were recruited, of which
  97 (20.08%) develop MCI.
- **Age:** The average age at enrollment of recruited participants is
  65.05 and of eligible participants is 65.61. The average age at onset
  is 70.26
- **Gender** Of recruited participants, 56.31% are male and 43.69% are
  female.
- **APOE4 Carrier Status** Of recruited participants, 30.02% are
  carriers and 69.98% are not carriers

## Biomarker data

``` r
mci_amyloid =
  read_csv('./data/data_mci/mci_amyloid.csv', skip = 1) |>
  janitor::clean_names() |>
  mutate(baseline = as.numeric(baseline)) |>  
  mutate(time_2 = as.numeric(time_2)) |>
  mutate(time_4 = as.numeric(time_4)) |>
  mutate(time_6 = as.numeric(time_6)) |>
  mutate(time_8 = as.numeric(time_8))
#skimr::skim(mci_amyloid)
```

The dataset details the ratio of amyloid beta in participants observed
at baseline and 4 follow-up time points. The average ratio is 0.11 at
baseline, 0.11 at two years, 0.11 at four years, 0.11 at six years, 0.11
at eight years.

There are 2 baseline values missing, 50 year 2 values missing, 43 year 4
values missing,39 year 6 values missing, and 38 year 8 values missing.

## Participant overlap

### Exploring patients only in one dataset

Check whether some participants appear in only the baseline or amyloid
datasets, and comment on your findings. Combine the demographic and
biomarker datasets so that only participants who appear in both datasets
are retained, and briefly describe the resulting dataset; export the
result as a CSV to your data directory.

``` r
mci_baseline_all = mci_baseline_all |> mutate(name = "baseline")
mci_amyloid = 
  mci_amyloid |> 
  mutate(name = "amyloid") |> 
  rename(id = study_id)

mci_all =
  full_join(mci_baseline_all, mci_amyloid, by = "id")
#mci_all
#skimr::skim(mci_all)
```

483 participants were recruited, 97 were eligible for inclusion. 487
have biomarker data recorded. There are 12 patients with no baseline
demographics but with biomarker data. There are 8 patients with baseline
demographics but no biomarker data. Presumably study recruitment and
retention is challenging, and so I would expect biomarker data to be
missing as it requires follow-up. However, it the inverse (that there
are participants with biomarker missing baseline demographics) is more
surprising.

### Generating CSV of Overlap

``` r
mci_overlap =
  inner_join(mci_baseline_all, mci_amyloid, by = "id") |> 
  select(-name.x, -name.y)
#mci_overlap
#skimr::skim(mci_overlap)

write_csv(mci_overlap, "./data/data_mci/mci_overlap.csv")
```

There are a total of 475 patients with both baseline and biomarker data.
They have an average age at enrollment of 65.07. There are 94 of these
patients who develop MCI.
